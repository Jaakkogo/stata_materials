{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More `bysort`, `merge` and multivariate regression using Stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "qui cd Z:/ECON-C4100 // change working dir\n",
    "qui use data/sweden_prices.dta, clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating unique observation within groups using bysort\n",
    "\n",
    "We start with `bysort` again. This time I demonstrate how you can use it to calculate the number of observations or products within some subgroups and variables. Quite often we are interested in calculating some group specific statistics such as sums, means and covariances (see the materials for Session 3). However, quite often we want to calculate the number of observations or more specifically, the number of **unique** or **distinct** observations.\n",
    "\n",
    "Let's demonstrate. We want to calculate how many products each company or `Företag` has on the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ". tab n_products1 if strpos(Företag, \"Orion\") > 0\n",
      "\n",
      "n_products1 |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "        132 |        515      100.00      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |        515      100.00\n"
     ]
    }
   ],
   "source": [
    "qui {\n",
    "    bysort Företag Produktnamn: gen n_products1 = _n == 1\n",
    "    bysort Företag: replace n_products1 = sum(n_products1)\n",
    "    bysort Företag: replace n_products1 = n_products1[_N]\n",
    "}\n",
    "tab n_products1 if strpos(Företag, \"Orion\") > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is shown above. Orion has 131 products at the market, separated by the product name.\n",
    "\n",
    "The above code does the following things:\n",
    "\n",
    "1. Bysort \"creates\" subgroups for `Företag` and `Produktnamn` with their own sort orders\n",
    "2. Tag the first value of each subgroup, ie. `_n == 1`\n",
    "3. Calculate the (rolling) sum of tags by `Företag` with `sum`.\n",
    "4. The total is the value of the last value of `Företag`, ie. `_N`.\n",
    "\n",
    "I call them them \"the Three Lines of God-tier Code\" because I use them so often. [Kudos to Nick Cox again!](https://www.stata.com/support/faqs/data-management/number-of-distinct-observations/)\n",
    "\n",
    "It's a nice trick to know and master even for cross-section data. But it's even better for panel data. The basic pricinple remains the same and can be stated as:\n",
    "\n",
    "```\n",
    "bysort timevar xvar zvar: gen nvals = _n == 1\n",
    "by timevar xvar: replace nvals = sum(nvals)\n",
    "by timevar xvar: replace nvals = nvals[_N]\n",
    "\n",
    "```\n",
    "\n",
    "Which calculates the number of distinct observations of `zvar` within `timevar` and `xvar`.\n",
    "\n",
    "\n",
    "However, there is also another way to do the same thing with `egen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ". tab n_products2 if strpos(Företag, \"Orion\") > 0\n",
      "\n",
      "n_products2 |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "        132 |        515      100.00      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |        515      100.00\n"
     ]
    }
   ],
   "source": [
    "qui {\n",
    "    egen n_products2_temp = tag(Företag Produktnamn)\n",
    "    bysort Företag: egen n_products2 = total(n_products2_temp)\n",
    "    drop n_products2_temp\n",
    "}\n",
    "tab n_products2 if strpos(Företag, \"Orion\") > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is the same.\n",
    "\n",
    "### Calculating imaginary sales data using `bysort`\n",
    "\n",
    "`bysort` is the go-to tool to calculate other stats too. Here I demonstrate how you can calculate company sales and market shares with imaginary simulated sales volume.\n",
    "\n",
    "It's an ugly demonstration but works for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ". tab market_share if strpos(Företag, \"Orion\") > 0 & strpos(ATCkod, \"C10AA01\") > 0\n",
      "\n",
      "market_shar |\n",
      "          e |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "   13.70447 |          7      100.00      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |          7      100.00\n"
     ]
    }
   ],
   "source": [
    "qui {\n",
    "    gen sales_volume =  runiform(1,5000)\n",
    "    bysort ATCkod: egen total_sales = total(sales_volume)\n",
    "    bysort ATCkod Företag: egen firm_sales = total(sales_volume)\n",
    "    gen market_share = (firm_sales/total_sales)*100\n",
    "}\n",
    "tab market_share if strpos(Företag, \"Orion\") > 0 & strpos(ATCkod, \"C10AA01\") > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate observations\n",
    "\n",
    "Duplicate observations are observations that have identical values in their variables. A natural way to calculate the number of duplicate observations by some variable list can be done using the `duplicates` command(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicates in terms of Produktnamn Varunummer ATCkod NPLid NPLpackid Form Styrka Förpackning Antal Företag AIP AUP AIPperst AUPperst Subventionerad dummy atc_1 cond_mean cond_mean_2 cond_mean_3 cond_mean_4 name_length correlation covariance n_products1\n",
      "    n_products2 sales_volume total_sales firm_sales market_share\n",
      "\n",
      "--------------------------------------\n",
      "   copies | observations       surplus\n",
      "----------+---------------------------\n",
      "        1 |        13953             0\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duplicates report _all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no perfect duplicates in our Swedish data. What about VNRs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicates in terms of Varunummer\n",
      "\n",
      "--------------------------------------\n",
      "   copies | observations       surplus\n",
      "----------+---------------------------\n",
      "        1 |        12770             0\n",
      "        2 |          514           257\n",
      "        3 |          279           186\n",
      "        4 |          144           108\n",
      "        5 |           40            32\n",
      "        6 |           78            65\n",
      "        7 |           56            48\n",
      "        8 |           24            21\n",
      "        9 |           18            16\n",
      "       10 |           30            27\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duplicates report Varunummer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations have the same VNR but different values for some of the other variables. Why?\n",
    "\n",
    "The answer: the cross-section variable in the Swedish data is not the Nordic article number (VNR) but `NPLpackid`. Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicates in terms of NPLpackid\n",
      "\n",
      "--------------------------------------\n",
      "   copies | observations       surplus\n",
      "----------+---------------------------\n",
      "        1 |        13953             0\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duplicates report NPLpackid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates. But we can create some using the `expand` command that creates duplicates from existing observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(13,953 observations created)\n",
      "\n",
      "\n",
      "Duplicates in terms of NPLpackid\n",
      "\n",
      "--------------------------------------\n",
      "   copies | observations       surplus\n",
      "----------+---------------------------\n",
      "        2 |        27906         13953\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "expand 2\n",
    "duplicates report NPLpackid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `expand` command is extremely useful when dealing with panel and time series data. But let's get back to the `duplicates` command. Or to be more specific, I'll demonstrate the `duplicates tag` and `duplicates drop` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Duplicates in terms of NPLpackid\n",
      "\n",
      "\n",
      "        tag |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |     13,953      100.00      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     13,953      100.00\n",
      "\n",
      "\n",
      "\n",
      "Duplicates in terms of NPLpackid\n",
      "\n",
      "(0 observations are duplicates)\n",
      "\n",
      "\n",
      "Duplicates in terms of NPLpackid\n",
      "\n",
      "--------------------------------------\n",
      "   copies | observations       surplus\n",
      "----------+---------------------------\n",
      "        1 |        13953             0\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duplicates tag NPLpackid, gen(tag)\n",
    "tab tag\n",
    "drop tag\n",
    "duplicates drop NPLpackid, force\n",
    "duplicates report NPLpackid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`duplicates tag` saves the number of surplus duplicates to a new variabe specified by the user. The `duplicates drop` command drops the duplicate observations (it also requires the option `force`).\n",
    "\n",
    "```{warning}\n",
    "\n",
    "You should not use `duplicates drop` without if you do not know which observations you are dealing with!\n",
    "\n",
    "```\n",
    "\n",
    "### Combining data sets - introduction to `merge`\n",
    "\n",
    "Quite often we want to use data from multiple source. How can we do that? We need at least:\n",
    "\n",
    "1. Some new data related to our current data\n",
    "2. key(s) to link you current data with the new data\n",
    "3. some command to do this for us\n",
    "\n",
    "Parts 1 and 2 are situational. But Stata can help us with the part 3 with the `merge` command. It is used to add new existing variables to our data.\n",
    "\n",
    "![](figures/merge.png)\n",
    "\n",
    "The data we want to add is the \"product of the month\" substitution data from Sweden.\n",
    "\n",
    "```{note}\n",
    "\n",
    "You may want to update our Swedish price data from Session 1. You can do this by importing it again and using `save` with `replace`.\n",
    "\n",
    "```\n",
    "\n",
    "We will other data combining functions more in detail in the next course.\n",
    "\n",
    "Let's clear the current memory and import it to Stata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Contains data\n",
      "  obs:         6,683                          \n",
      " vars:            17                          \n",
      " size:     2,459,344                          \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              storage   display    value\n",
      "variable name   type    format     label      variable label\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Status          str3    %9s                   Status\n",
      "Produktnamn     str50   %50s                  Produktnamn\n",
      "Varunummer      str6    %9s                   Varunummer\n",
      "Styrka          str36   %36s                  Styrka\n",
      "Förpackningss~p str8    %9s                   Förpackningsstorleksgrupp\n",
      "Substans        str56   %56s                  Substans\n",
      "Beredningsform  str66   %66s                  Beredningsform\n",
      "Storlek         double  %10.0g                Storlek\n",
      "Apotekensinkö~s double  %10.0g                Apotekens inköpspris\n",
      "Försäljningsp~s double  %10.0g                Försäljningspris\n",
      "Inköpsprisper~t double  %10.0g                Inköpspris per minsta enhet\n",
      "Försäljningsp~e double  %10.0g                Försäljningspris per minsta enhet\n",
      "NPLID           str14   %14s                  NPL ID\n",
      "NPLpackID       str14   %14s                  NPL pack ID\n",
      "Ursprung        str20   %20s                  Ursprung\n",
      "Företag         str49   %49s                  Företag\n",
      "UtbytesgruppsID str6    %9s                   Utbytesgrupps ID\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Sorted by: \n",
      "     Note: Dataset has changed since last saved.\n"
     ]
    }
   ],
   "source": [
    "clear all\n",
    "import excel using ///\n",
    "\"https://www.tlv.se/webdav/files/Periodens-vara/periodens-vara-februari-20210201.xlsx\", ///\n",
    "firstrow clear // variable names in first row\n",
    "describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep only `NPLpackID`, `UtbytesgruppsID` and `Status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep NPLpackID UtbytesgruppsID Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our key for combining data is `NPLpackID`. For the `merge` to work, the variable names in our two data sets have to be equal. We'll have to `rename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename NPLpackID NPLpackid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can `merge`. There are three variants of merge:\n",
    "\n",
    "0. 1 to 1\n",
    "1. 1 to many\n",
    "2. many to 1 \n",
    "3. many to many\n",
    "\n",
    "The first one means that there are more than 1 observations for our key in the other data set. The second means that we have duplicates for our key in this data set but there is only one value in the other data set. The many-to-many merge exists, but the Stata manual says that you should never use it.\n",
    "\n",
    "We have 1:1 merge because we are using the `NPLpackid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Result                           # of obs.\n",
      "    -----------------------------------------\n",
      "    not matched                         7,270\n",
      "        from master                         0  (_merge==1)\n",
      "        from using                      7,270  (_merge==2)\n",
      "\n",
      "    matched                             6,683  (_merge==3)\n",
      "    -----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "merge 1:1 NPLpackid using \"Z:/ECON-C4100/data/sweden_prices.dta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tells us that slightly less than half of the observations were matched. The information whether some observation was matched is saved in the variable `_merge` by default.\n",
    "\n",
    "With our new data, we can `generate` a new variable for the substitution status. This time we will call it the \"product of the month status\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  pm_status |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |      7,270       52.10       52.10\n",
      "          1 |      6,683       47.90      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     13,953      100.00\n"
     ]
    }
   ],
   "source": [
    "gen pm_status = _merge == 3\n",
    "tab pm_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also add a dummy for each ATC level 1 in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "      atc_1 |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          A |      1,408       10.09       10.09\n",
      "          B |        956        6.85       16.94\n",
      "          C |      1,429       10.24       27.18\n",
      "          D |        412        2.95       30.14\n",
      "          G |        544        3.90       34.04\n",
      "          H |        400        2.87       36.90\n",
      "          J |      1,032        7.40       44.30\n",
      "          L |      1,754       12.57       56.87\n",
      "          M |        403        2.89       59.76\n",
      "          N |      4,408       31.59       91.35\n",
      "          P |         45        0.32       91.67\n",
      "          R |        691        4.95       96.62\n",
      "          S |        349        2.50       99.13\n",
      "          V |        122        0.87      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     13,953      100.00\n"
     ]
    }
   ],
   "source": [
    "egen atc1_group = group(atc_1), label\n",
    "tab atc_1, gen(atc_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "group(atc_1 |\n",
      "          ) |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          A |      1,408       10.09       10.09\n",
      "          B |        956        6.85       16.94\n",
      "          C |      1,429       10.24       27.18\n",
      "          D |        412        2.95       30.14\n",
      "          G |        544        3.90       34.04\n",
      "          H |        400        2.87       36.90\n",
      "          J |      1,032        7.40       44.30\n",
      "          L |      1,754       12.57       56.87\n",
      "          M |        403        2.89       59.76\n",
      "          N |      4,408       31.59       91.35\n",
      "          P |         45        0.32       91.67\n",
      "          R |        691        4.95       96.62\n",
      "          S |        349        2.50       99.13\n",
      "          V |        122        0.87      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |     13,953      100.00\n",
      "\n",
      "\n",
      "              storage   display    value\n",
      "variable name   type    format     label      variable label\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "atc_dummy1      byte    %8.0g                 atc_1==A\n",
      "atc_dummy2      byte    %8.0g                 atc_1==B\n",
      "atc_dummy3      byte    %8.0g                 atc_1==C\n",
      "atc_dummy4      byte    %8.0g                 atc_1==D\n",
      "atc_dummy5      byte    %8.0g                 atc_1==G\n",
      "atc_dummy6      byte    %8.0g                 atc_1==H\n",
      "atc_dummy7      byte    %8.0g                 atc_1==J\n",
      "atc_dummy8      byte    %8.0g                 atc_1==L\n",
      "atc_dummy9      byte    %8.0g                 atc_1==M\n",
      "atc_dummy10     byte    %8.0g                 atc_1==N\n",
      "atc_dummy11     byte    %8.0g                 atc_1==P\n",
      "atc_dummy12     byte    %8.0g                 atc_1==R\n",
      "atc_dummy13     byte    %8.0g                 atc_1==S\n",
      "atc_dummy14     byte    %8.0g                 atc_1==V\n"
     ]
    }
   ],
   "source": [
    "tab atc1_group\n",
    "describe atc_dummy*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple regressions using Stata\n",
    "\n",
    "Doing multiple regressions using Stata is as easy as univariate regressions. We simply add more variables to the equation. Let's continue with our light-hearted example from the previous session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note: atc_dummy11 omitted because of collinearity\n",
      "\n",
      "Linear regression                               Number of obs     =     13,953\n",
      "                                                F(15, 13937)      =      67.36\n",
      "                                                Prob > F          =     0.0000\n",
      "                                                R-squared         =     0.1229\n",
      "                                                Root MSE          =      10160\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "         AIP |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      " name_length |  -176.9473   10.54853   -16.77   0.000    -197.6239   -156.2708\n",
      "   pm_status |  -1862.504    171.648   -10.85   0.000    -2198.957   -1526.051\n",
      "  atc_dummy1 |     632.32    316.969     1.99   0.046     11.01831    1253.622\n",
      "  atc_dummy2 |   4003.285   588.1725     6.81   0.000     2850.388    5156.183\n",
      "  atc_dummy3 |   1519.962   288.2879     5.27   0.000     954.8786    2085.045\n",
      "  atc_dummy4 |  -262.6696   264.3871    -0.99   0.320    -780.9038    255.5646\n",
      "  atc_dummy5 |  -409.0312   255.0316    -1.60   0.109    -908.9273    90.86498\n",
      "  atc_dummy6 |   2590.807    417.682     6.20   0.000     1772.094     3409.52\n",
      "  atc_dummy7 |   4486.223   643.9131     6.97   0.000     3224.067    5748.379\n",
      "  atc_dummy8 |   9774.207   464.0406    21.06   0.000     8864.625    10683.79\n",
      "  atc_dummy9 |    1726.34   678.0852     2.55   0.011     397.2021    3055.478\n",
      " atc_dummy10 |   473.4766   254.8002     1.86   0.063    -25.96589    972.9191\n",
      " atc_dummy11 |          0  (omitted)\n",
      " atc_dummy12 |   3024.402   694.9133     4.35   0.000     1662.279    4386.526\n",
      " atc_dummy13 |  -850.3503   263.4682    -3.23   0.001    -1366.783   -333.9172\n",
      " atc_dummy14 |   1069.107   400.7182     2.67   0.008     283.6458    1854.569\n",
      "       _cons |   3582.007   294.5745    12.16   0.000     3004.601    4159.412\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "reg AIP name_length pm_status atc_dummy*, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have also typed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear regression                               Number of obs     =     13,953\n",
      "                                                F(15, 13937)      =      67.36\n",
      "                                                Prob > F          =     0.0000\n",
      "                                                R-squared         =     0.1229\n",
      "                                                Root MSE          =      10160\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "         AIP |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      " name_length |  -176.9473   10.54853   -16.77   0.000    -197.6239   -156.2708\n",
      "   pm_status |  -1862.504    171.648   -10.85   0.000    -2198.957   -1526.051\n",
      "             |\n",
      "  atc1_group |\n",
      "          B  |   3370.965   573.2447     5.88   0.000     2247.329    4494.602\n",
      "          C  |   887.6416   230.0974     3.86   0.000     436.6198    1338.663\n",
      "          D  |  -894.9896   219.6701    -4.07   0.000    -1325.573   -464.4067\n",
      "          G  |  -1041.351   210.4891    -4.95   0.000    -1453.938   -628.7643\n",
      "          H  |   1958.487   388.5961     5.04   0.000     1196.786    2720.187\n",
      "          J  |   3853.903   612.3809     6.29   0.000     2653.554    5054.252\n",
      "          L  |   9141.887   442.1455    20.68   0.000     8275.222    10008.55\n",
      "          M  |    1094.02   649.5993     1.68   0.092    -179.2816    2367.322\n",
      "          N  |  -158.8434   198.3489    -0.80   0.423    -547.6338     229.947\n",
      "          P  |    -632.32    316.969    -1.99   0.046    -1253.622   -11.01831\n",
      "          R  |   2392.082   676.1316     3.54   0.000     1066.774    3717.391\n",
      "          S  |   -1482.67   221.8531    -6.68   0.000    -1917.532   -1047.808\n",
      "          V  |   436.7873   377.9722     1.16   0.248    -304.0889    1177.663\n",
      "             |\n",
      "       _cons |   4214.327   277.3235    15.20   0.000     3670.736    4757.918\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "reg AIP name_length pm_status i.atc1_group, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few important things to notive. First of all, `i.` in front of some variable means that we want Stata to consider this variable as a **categorical** variable. Stata will automatically add the dummy variables for us. Remember that one dummy goes always to zero because of multicollinearity.\n",
    "\n",
    "Second of all, we've used the option `r` in our regressions. This tells Stata to calculate robust standard errors that allow for heteroscedasticity. We will use this option in all of our estimations in the future and so should you.\n",
    "\n",
    "Finally, let's transform some of the variables to natural logs and run our regression again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Linear regression                               Number of obs     =     13,953\n",
      "                                                F(15, 13937)      =     561.18\n",
      "                                                Prob > F          =     0.0000\n",
      "                                                R-squared         =     0.3903\n",
      "                                                Root MSE          =       1.48\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "      ln_AIP |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "  ln_nlength |  -.6799245   .0298059   -22.81   0.000     -.738348    -.621501\n",
      "   pm_status |    -.99519   .0297118   -33.49   0.000    -1.053429   -.9369509\n",
      "             |\n",
      "  atc1_group |\n",
      "          B  |   1.380389   .0603043    22.89   0.000     1.262185    1.498594\n",
      "          C  |  -.0759281   .0557473    -1.36   0.173    -.1852003    .0333442\n",
      "          D  |  -.2234432   .0758802    -2.94   0.003    -.3721786   -.0747077\n",
      "          G  |   .0334417   .0648877     0.52   0.606    -.0937469    .1606304\n",
      "          H  |   1.072565   .0996964    10.76   0.000     .8771467    1.267983\n",
      "          J  |   .8185149   .0694894    11.78   0.000     .6823063    .9547236\n",
      "          L  |   2.341384   .0557629    41.99   0.000     2.232081    2.450687\n",
      "          M  |  -.1340736   .0876596    -1.53   0.126    -.3058982    .0377511\n",
      "          N  |    .199959    .042192     4.74   0.000     .1172569    .2826611\n",
      "          P  |  -.3629877   .2280811    -1.59   0.112    -.8100573     .084082\n",
      "          R  |   .3562219   .0680349     5.24   0.000     .2228644    .4895794\n",
      "          S  |  -.6855587   .0641376   -10.69   0.000     -.811277   -.5598403\n",
      "          V  |   1.415148   .0988852    14.31   0.000     1.221319    1.608976\n",
      "             |\n",
      "       _cons |   7.511801   .0784276    95.78   0.000     7.358072     7.66553\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gen ln_nlength = ln(name_length)\n",
    "gen ln_AIP = ln(AIP)\n",
    "reg ln_AIP ln_nlength pm_status i.atc1_group, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file data/sweden_prices_merged.dta saved\n"
     ]
    }
   ],
   "source": [
    "save data/sweden_prices_merged.dta, replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata",
   "language": "stata",
   "name": "stata"
  },
  "language_info": {
   "codemirror_mode": "stata",
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
